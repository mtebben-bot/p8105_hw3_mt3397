---
title: "Homework 3"
output: github_document
---

```{r setup, include = FALSE}
library(tidyverse)
library(p8105.datasets)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

```{r load data}
data("instacart")
```

This dataset has `r nrow(instacart)` rows and `r ncol(instacart)` columns.

There are variables based on the user/order -- user ID, order ID, order number, order day, order hour. There are also variables based on the item -- name, aisle, department, product ID.

#### How many aisles, and which aisles are the most items ordered from?

```{r aisles}
aisles_count = 
  instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

There are `r nrow(aisles_count)` aisles and most items are ordered from fresh vegetables and fresh fruits.

#### Time to make a plot

```{r aisles plot}
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>% 
  ggplot(aes(x = aisle, y = n))+
  geom_point()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

#### Three most popular items in the aisles "baking ingredients", "dog food care", and "packaged vegetables fruits".

```{r table popular items}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(aisle, rank) %>% 
  knitr::kable()
```

#### Table for mean hour of the day where Pink Lady Apples and Coffee Ice Cream are ordered

```{r apples n ice cream}
instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  )
```


## Problem 2

#### Loading, tidying, and otherwise wrangling the data.

```{r import data}
accel_df = 
  read.csv("data/accel_data.csv") %>% 
  pivot_longer( activity.1:activity.1440,
    names_to = "minute",
    names_prefix = "activity.",
    values_to = "activity_count"
  ) %>% 
  mutate(
    day = factor(day),
    minute = as.numeric(minute),
    weekday_weekend = recode(day, "Monday" = "weekday", "Tuesday" = "weekday", "Wednesday" = "weekday", "Thursday" = "weekday", "Friday" = "weekday", "Saturday" = "weekend", "Sunday" = "weekend"))
```

There are `r nrow(accel_df)` observations in this dataset. There are variables to describe the time of the observation -- weekday vs. weekend, week of the observation, day of the observation, and minute of the day of the observation. There is the activity_count variable to describe the value of the activity count.


#### Aggregate across minutes to create a total activity variable for each day.

```{r aggregate}
agg_accel = 
  accel_df %>% 
  group_by(day) %>% 
  summarize(total_activity = sum(activity_count)) %>% 
  mutate(rank = min_rank(desc(total_activity))) %>% 
  arrange(rank) %>% 
  knitr::kable()
```

It seems like he is most active towards the end of the week and is less active on the weekends and beginnings of the week. He is most active on Fridays.

#### Plot of activity over 24 hours by day of the week.

```{r plot activity}
accel_df %>% 
  ggplot(aes(x = minute, y = activity_count, color = day))+
  labs(
    title = "Activity Count over 24 Hours by Day of the Week",
    x = "Time of the Day (minutes)",
    y = "Activity Count",
    caption = "Data from 63-year-old patient at CUMC"
  )+
  geom_smooth(se = F)
```

It seems like most of his activity on Sundays happened in the mornings, while most of his activity on Fridays happened in the evenings.

## Problem 3

```{r load NOAA data}
data("ny_noaa")
colSums(is.na(ny_noaa))
```

The dataset has `r nrow(ny_noaa)` observations and `r ncol(ny_noaa)` variables. There is a variable to describe the observation location, the date of the observation, as well as precipitation, snowfall, and temperature readings. The precipitation, snowfall, and snowdepth are measured in tenths of millimeters and millimeters respectively, and temperature is recorded in tenths of degrees Celsius. This is a very large dataset, but it has a lot of missing values, sometimes spanning weeks or months at a time.

#### Tidying `ny_noaa` dataset

We want to separate the date variable into year, month, and day, and we want to make temperature readings into numeric variables. Additionally, we want to change measurements into centimeters and temperatures into Celsius.

```{r tidy data}
noaa1 = 
  ny_noaa %>% 
   separate(date, into = c("year", "month", "day")) %>% 
   mutate(tmin = as.numeric(tmin),
          tmax = as.numeric(tmax),
          snow = snow/10,
          prcp = prcp/100,
          snwd = snwd/10,
          tmax = tmax/10,
          tmin = tmin/10) 
noaa_snow =
  noaa1 %>% 
  count(snow) %>% 
  mutate(rank = min_rank(snow)) %>% 
  arrange(rank)
```

The most commonly observed snowfall data is 0 cm. This is not surprising because we have data for the entirety of each year in this dataset, and it is unlikely to snow for the majority of months in New York.



